services:
  # --- INFRASTRUCTURE ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.2
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.2.2
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
    command: server /data --console-address ":9001"

  dbt:
    image: ghcr.io/dbt-labs/dbt-snowflake:latest
    container_name: dbt_transform
    volumes:
      - ./dbt:/usr/app/dbt
      - ~/.dbt:/root/.dbt  
    environment:
      - SNOWFLAKE_ACCOUNT=${SNOWFLAKE_ACCOUNT}
      - SNOWFLAKE_USER=${SNOWFLAKE_USER}
      - SNOWFLAKE_PASSWORD=${SNOWFLAKE_PASSWORD}
    profiles: ["transform"] # Pour ne le lancer que si besoin

  # --- AIRFLOW ---
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data # Persistance des données

  airflow-init:
    image: apache/airflow:2.7.1
    depends_on:
      - postgres
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    # On force l'initialisation et la création de l'utilisateur en une fois
    command: >
      bash -c "airflow db init && 
      airflow users create --username admin --firstname Mahdi --lastname BenArfi --role Admin --email admin@example.com --password admin"

  airflow-webserver:
    image: apache/airflow:2.7.1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=ma_cle_secrete_tres_sure
      - PIP_ADDITIONAL_REQUIREMENTS=boto3 apache-airflow-providers-snowflake apache-airflow-providers-docker dbt-core dbt-snowflake
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ~/.dbt:/home/airflow/.dbt
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.7.1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=ma_cle_secrete_tres_sure
      - _PIP_ADDITIONAL_REQUIREMENTS=boto3 apache-airflow-providers-snowflake dbt-core dbt-snowflake
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ~/.dbt:/home/airflow/.dbt
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
    command: scheduler

volumes:
  postgres_data: